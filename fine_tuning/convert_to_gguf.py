import os
import argparse
import subprocess

def convert_model(model_dir, output_name):
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ –≤ GGUF...")

    convert_script = os.path.join("llama.cpp", "convert.py")
    if not os.path.isfile(convert_script):
        raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω convert.py –∏–∑ llama.cpp. –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç—ã –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–ª —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.")

    cmd = [
        "python3", convert_script,
        "--outfile", output_name,
        "--tokenizer_path", model_dir,
        "--model_path", model_dir,
        "--model_type", "gemma"
    ]

    print(f"üõ† –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞: {' '.join(cmd)}")
    subprocess.run(cmd, check=True)

    print("‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å HuggingFace –≤ GGUF —Ñ–æ—Ä–º–∞—Ç –¥–ª—è llama.cpp")
    parser.add_argument("--model_dir", type=str, default="merged_model", help="–ü—É—Ç—å –¥–æ –º–æ–¥–µ–ª–∏ (merged PEFT)")
    parser.add_argument("--output_name", type=str, default="gemma-1b-it.gguf", help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ GGUF-—Ñ–∞–π–ª–∞")

    args = parser.parse_args()
    convert_model(args.model_dir, args.output_name)
