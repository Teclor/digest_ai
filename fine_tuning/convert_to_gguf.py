import os
import argparse
import subprocess

def convert_model(model_dir, output_name):
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ –≤ GGUF...")

    convert_script = os.path.join("llama.cpp", "convert_hf_to_gguf.py")
    if not os.path.isfile(convert_script):
        raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω convert_hf_to_gguf.py –∏–∑ llama.cpp. –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç—ã –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–ª —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.")

    cmd = [
        "python3", convert_script,
        model_dir,  # –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç –≤–º–µ—Å—Ç–æ --model_path –∏ —Ç.–ø.
        "--outfile", output_name,
        "--outtype", "f16",  # –∏–ª–∏ q8_0, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –∫–≤–∞–Ω—Ç–æ–≤–∞—Ç—å
        "--verbose"
    ]

    print(f"üõ† –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞: {' '.join(cmd)}")
    subprocess.run(cmd, check=True)

    print("‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å HuggingFace –≤ GGUF —Ñ–æ—Ä–º–∞—Ç –¥–ª—è llama.cpp")
    parser.add_argument("--model_dir", type=str, default="merged_model", help="–ü—É—Ç—å –¥–æ –º–æ–¥–µ–ª–∏ (merged PEFT)")
    parser.add_argument("--output_name", type=str, default="gemma_tuned_remote_75k.gguf", help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ GGUF-—Ñ–∞–π–ª–∞")

    args = parser.parse_args()
    convert_model(args.model_dir, args.output_name)
