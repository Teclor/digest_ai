import os
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

BASE_MODEL = "unsloth/gemma-3-1b-it-qat"
PEFT_MODEL_PATH = "output"  # –ü–∞–ø–∫–∞, –∫—É–¥–∞ Trainer —Å–æ—Ö—Ä–∞–Ω—è–ª LoRA –≤–µ—Å–∞
MERGED_MODEL_PATH = "merged_model"

def merge_lora_and_save():
    print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å...")
    base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype="auto")

    print("ü™Ñ –ó–∞–≥—Ä—É–∂–∞–µ–º PEFT (LoRA) –≤–µ—Å–∞...")
    peft_model = PeftModel.from_pretrained(base_model, PEFT_MODEL_PATH)

    print("üîó –°–ª–∏–≤–∞–µ–º LoRA –≤ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å...")
    merged_model = peft_model.merge_and_unload()

    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤: {MERGED_MODEL_PATH}")
    os.makedirs(MERGED_MODEL_PATH, exist_ok=True)
    merged_model.save_pretrained(MERGED_MODEL_PATH)

    print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä...")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)
    tokenizer.save_pretrained(MERGED_MODEL_PATH)

    print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")

if __name__ == "__main__":
    merge_lora_and_save()
